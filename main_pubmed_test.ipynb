{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pubmedFetcher import pubmedResults\n",
    "from glyphilator import wordlists_from_folder,generateGlyphInput,constructBasicGlyphs,chooseBasicColors,generate_centered_grid\n",
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "search_url = r\"https://pubmed.ncbi.nlm.nih.gov/?term=ttis&size=200\"\n",
    "wordlists_path = r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\wordlists\\group_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(2.019014084507042), np.float64(1.0577464788732394), np.float64(1.4866197183098588), np.float64(1.116901408450704), np.float64(0.5401408450704225), np.float64(0.732394366197183), np.float64(1.2352112676056335), np.float64(0.3183098591549296)]\n",
      "[2.01702128 1.76153846 2.3        1.20153846 1.62058824 1.80851064\n",
      " 1.79230769 0.66666667]\n",
      "0.30043340008705854 0.21211980003863573\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data_array = np.array([[123, 58, 87, 62, 23, 36, 70, 8], \n",
    "        [92, 72, 44, 22, 15, 43, 59, 36], \n",
    "        [94, 30, 35, 53, 9, 32, 37, 11], \n",
    "        [135, 45, 52, 53, 10, 41, 67, 31], \n",
    "        [51, 16, 19, 42, 8, 15, 28, 5], \n",
    "        [51, 21, 22, 27, 7, 23, 49, 9], \n",
    "        [103, 53, 41, 81, 27, 38, 92, 21], \n",
    "        [14, 8, 7, 14, 3, 3, 8, 0], \n",
    "        [105, 36, 34, 96, 23, 18, 54, 21], \n",
    "        [116, 54, 61, 42, 34, 45, 79, 25], \n",
    "        [102, 47, 34, 130, 18, 30, 65, 20], \n",
    "        [67, 35, 23, 42, 16, 20, 45, 11], \n",
    "        [108, 28, 40, 98, 25, 32, 76, 13], \n",
    "        [1, 0, 1, 0, 0, 0, 1, 0], \n",
    "        [113, 49, 54, 37, 18, 36, 61, 18], \n",
    "        [1, 0, 1, 0, 0, 0, 1, 0], \n",
    "        [61, 25, 45, 48, 20, 22, 43, 20], \n",
    "        [122, 51, 52, 38, 24, 47, 65, 19], \n",
    "        [73, 23, 15, 52, 3, 21, 47, 13], \n",
    "        [142, 78, 49, 83, 12, 17, 87, 21]])\n",
    "\n",
    "\n",
    "# Custom scaling implementation\n",
    "def custom_scaling():\n",
    "    min_val = np.min(data_array)\n",
    "    max_val = np.max(data_array)\n",
    "    return float([[0.2 + (x - min_val) * (2.3 - 0.2) / (max_val - min_val) for x in row] for row in data_array])\n",
    "\n",
    "print(custom_scaling()[0])\n",
    "\n",
    "# Using MinMaxScaler\n",
    "def sklearn_scaling():\n",
    "    scaler = MinMaxScaler(feature_range=(0.2, 2.3))\n",
    "    return scaler.fit_transform(data_array)\n",
    "print(sklearn_scaling()[0])\n",
    "# Time both methods\n",
    "time_custom = timeit.timeit(custom_scaling, number=1000)\n",
    "time_sklearn = timeit.timeit(sklearn_scaling, number=1000)\n",
    "\n",
    "print(time_custom,time_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists = wordlists_from_folder(wordlists_path)\n",
    "print(\"Wordlists generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleData = pubmedResults(search_url=search_url, num_results_requested=6)\n",
    "articleData = pubmedResults(search_url=search_url, num_results_requested=6)\n",
    "print(\"articleData compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allGlyphData = generateGlyphInput(articleData=articleData,wordlists=wordlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antzfile,tagfile = constructBasicGlyphs(allGlyphData,articleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antzfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\0_DO_NOT_DELETE - Copy\\articleScraperOutput\\csv\\articleScraperOutput_np_node.csv\",index=False,encoding=\"utf-8\")\n",
    "tagfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\0_DO_NOT_DELETE - Copy\\articleScraperOutput\\csv\\articleScraperOutput_np_tag.csv\",index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "#create a new directory each time the button is pressed, storing the new viz\n",
    "current_date = str(datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "\n",
    "current_time = datetime.datetime.now().strftime('%H%M%S')\n",
    "\n",
    "date_directory_path = os.path.join(cwd,'antz','gaia_2024-07-24_app_v2','User','Prototypes', current_date)\n",
    "\n",
    "    #making the date directory in antz/user/prototypes\n",
    "try:\n",
    "    os.mkdir(date_directory_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "time_directory_path = os.path.join(date_directory_path,current_time)\n",
    "\n",
    "\n",
    "os.mkdir(time_directory_path)\n",
    "directory1 = pathlib.Path(os.path.join(cwd,\"antz\",\"gaia_2024-07-24_app_v2\", \"User\", \"Prototypes\", \"0_DO_NOT_DELETE\", \"articleScraperOutput\"))\n",
    "\n",
    "for file in directory1.rglob(\"*\"):\n",
    "    print(file)\n",
    "    destination = time_directory_path / file.relative_to(directory1)\n",
    "\n",
    "    if file.is_file():\n",
    "        # Ensure parent directory exists in destination, then copy the file\n",
    "        # time_directory_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(file, destination)\n",
    "    elif file.is_dir():\n",
    "        # Ensure the directory exists in the destination\n",
    "        destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# node_filename = str(current_time) + \"_np_node.csv\"\n",
    "# tag_filename = str(current_time) + \"_np_tag.csv\"\n",
    "# #replacing articleScraperOutput_np_node, and articleScraperOutput_np_tag with our newly calculated versions\n",
    "# os.remove(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_node.csv\")))\n",
    "# os.remove(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_tag.csv\")))\n",
    "\n",
    "# antzfile.to_csv(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_node.csv\")),index=False,encoding=\"utf-8\")\n",
    "# tagfile.to_csv(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_tag.csv\")),index=False,encoding=\"utf-8\")\n",
    "\n",
    "# antzfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\2024-11-07\\52148\\csv\\articleScraperOutput_np_node.csv\")\n",
    "# tagfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\2024-11-07\\52148\\csv\\articleScraperOutput_np_tag.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
