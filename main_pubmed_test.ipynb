{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncPubmedFetcher import pubmedResults\n",
    "from glyphilator import wordlists_from_folder,generateGlyphInput,constructBasicGlyphs,chooseBasicColors,generate_centered_grid\n",
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "search_url = r\"https://pubmed.ncbi.nlm.nih.gov/?term=ttis&size=200\"\n",
    "wordlists_path = r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\wordlists\\group_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordlists generated\n"
     ]
    }
   ],
   "source": [
    "wordlists = wordlists_from_folder(wordlists_path)\n",
    "print(\"Wordlists generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles Processed:  1 / 2\n",
      "Articles Processed:  2 / 2\n"
     ]
    }
   ],
   "source": [
    "articleData = pubmedResults(search_url,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract parsed 1 / 2\n",
      "Abstract parsed 2 / 2\n",
      "scaling_scope is: dataset\n"
     ]
    }
   ],
   "source": [
    "allGlyphData = generateGlyphInput(articleData=articleData,wordlists=wordlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we got past manager\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m         wordlist_abs_path \u001b[38;5;241m=\u001b[39m wordlists_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[0;32m      7\u001b[0m         list_txt_filepaths\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(wordlist_abs_path,antz_base_path))\n\u001b[1;32m----> 8\u001b[0m antzfile,tagfile \u001b[38;5;241m=\u001b[39m \u001b[43mconstructBasicGlyphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallGlyphData\u001b[49m\u001b[43m,\u001b[49m\u001b[43marticleData\u001b[49m\u001b[43m,\u001b[49m\u001b[43msearch_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometrySelection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mToroid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwordlist_paths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_txt_filepaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_results_requested\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscaling_range\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscaling_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscaling_scope\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_matched_words\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotos_save_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath/to/antz/save/dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\glyphilator.py:454\u001b[0m, in \u001b[0;36mconstructBasicGlyphs\u001b[1;34m(articleData, wordlists, search_metadata)\u001b[0m\n\u001b[0;32m    451\u001b[0m tagfile \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(tag_file_path)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m#calling generateGlyphInput to get allglyphdata, the antz ring scale value, and glyphdatacounts, to get the #hits from each wordlist for each tag\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m allGlyphData,glyphDataCounts,articleLengths,articleWordcounts,matched_words \u001b[38;5;241m=\u001b[39m \u001b[43mgenerateGlyphInputConcurrent\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticleData\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwordlists\u001b[49m\u001b[43m,\u001b[49m\u001b[43msearch_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m num_rings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(allGlyphData[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m#check len of a single glyph list. for each index in the list we'll make a ring\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# print(\"num rings = \",num_rings)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\glyphilator.py:297\u001b[0m, in \u001b[0;36mgenerateGlyphInputConcurrent\u001b[1;34m(articleData, wordlists, search_metadata)\u001b[0m\n\u001b[0;32m    294\u001b[0m articleWordcounts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m matched_words \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 297\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglyphData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatched\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallGlyphData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglyphData\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\process.py:642\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "antz_base_path = os.path.join(os.getcwd(), \"antz\", \"antz\")\n",
    "wordlists = os.listdir(wordlists_path) # i need to copy the paths this way because thats how i make the wordlists in glyphilator function. Dont wanna risk pathlib putting wordlists out of order\n",
    "list_txt_filepaths = []\n",
    "for file in wordlists:\n",
    "    if file.endswith('.txt'):\n",
    "        wordlist_abs_path = wordlists_path + r\"\\\\\" + file\n",
    "        list_txt_filepaths.append(os.path.relpath(wordlist_abs_path,antz_base_path))\n",
    "antzfile,tagfile = constructBasicGlyphs(allGlyphData,articleData,search_metadata = {\n",
    "                                            \"geometrySelection\": \"Toroid\", \n",
    "                                            \"wordlist_paths\" : list_txt_filepaths,\n",
    "                                            \"search_string\": \"sample string\",\n",
    "                                            \"num_results_requested\": 200,\n",
    "                                            \"scaling_range\": (0.2,2.5),\n",
    "                                            \"scaling_type\": \"minmax\",\n",
    "                                            \"scaling_scope\":\"dataset\",\n",
    "                                            \"save_matched_words\":False,\n",
    "                                            \"protos_save_path\":\"path/to/antz/save/dir\"}\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antzfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\0_DO_NOT_DELETE - Copy\\articleScraperOutput\\csv\\articleScraperOutput_np_node.csv\",index=False,encoding=\"utf-8\")\n",
    "tagfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\0_DO_NOT_DELETE - Copy\\articleScraperOutput\\csv\\articleScraperOutput_np_tag.csv\",index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "#create a new directory each time the button is pressed, storing the new viz\n",
    "current_date = str(datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "\n",
    "current_time = datetime.datetime.now().strftime('%H%M%S')\n",
    "\n",
    "date_directory_path = os.path.join(cwd,'antz','gaia_2024-07-24_app_v2','User','Prototypes', current_date)\n",
    "\n",
    "    #making the date directory in antz/user/prototypes\n",
    "try:\n",
    "    os.mkdir(date_directory_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "time_directory_path = os.path.join(date_directory_path,current_time)\n",
    "\n",
    "\n",
    "os.mkdir(time_directory_path)\n",
    "directory1 = pathlib.Path(os.path.join(cwd,\"antz\",\"gaia_2024-07-24_app_v2\", \"User\", \"Prototypes\", \"0_DO_NOT_DELETE\", \"articleScraperOutput\"))\n",
    "\n",
    "for file in directory1.rglob(\"*\"):\n",
    "    print(file)\n",
    "    destination = time_directory_path / file.relative_to(directory1)\n",
    "\n",
    "    if file.is_file():\n",
    "        # Ensure parent directory exists in destination, then copy the file\n",
    "        # time_directory_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(file, destination)\n",
    "    elif file.is_dir():\n",
    "        # Ensure the directory exists in the destination\n",
    "        destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# node_filename = str(current_time) + \"_np_node.csv\"\n",
    "# tag_filename = str(current_time) + \"_np_tag.csv\"\n",
    "# #replacing articleScraperOutput_np_node, and articleScraperOutput_np_tag with our newly calculated versions\n",
    "# os.remove(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_node.csv\")))\n",
    "# os.remove(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_tag.csv\")))\n",
    "\n",
    "# antzfile.to_csv(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_node.csv\")),index=False,encoding=\"utf-8\")\n",
    "# tagfile.to_csv(str(os.path.join(time_directory_path,'csv',\"articleScraperOutput_np_tag.csv\")),index=False,encoding=\"utf-8\")\n",
    "\n",
    "# antzfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\2024-11-07\\52148\\csv\\articleScraperOutput_np_node.csv\")\n",
    "# tagfile.to_csv(r\"C:\\Users\\aglis\\Documents\\Python_Projects\\DaveArticleScraper\\antz\\gaia_2024-07-24_app_v2\\User\\Prototypes\\2024-11-07\\52148\\csv\\articleScraperOutput_np_tag.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
